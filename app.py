import streamlit as st
import base64
import requests
from bs4 import BeautifulSoup
import os
import pandas as pd
from textblob import TextBlob

# Set page configuration with a title and icon
st.set_page_config(
    page_title="Darlbit Word Subsumption",
    page_icon="ğŸ“š"
)

# Custom CSS
st.markdown(
    """
    <style>
    body {
        background-image: url('https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxlrcU%2FbtsyynNTUpV%2F645uH8YylBDseYgqvXXK5k%2Fimg.png');
        background-size: cover;
    }
    h1 {
        color: #4CAF50;
    }
    .link-box {
        padding: 10px;
        border: 2px solid #4CAF50;
        border-radius: 5px;
        margin: 5px;
        background-color: #f9f9f9;
        text-align: center;
    }
    img {
        max-height: 200px;
    }
    .streamlit-expanderContent {
        display: flex;
        flex-direction: column;
        align-items: center;
    }
    [data-testid="stExpander"] button {
        display: none;
    }
    .streamlit-expanderHeader {
        pointer-events: none;
    }
    [data-testid="stImage"] button {
        display: none;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Initialize session state for words and deleted words if not already done
if 'words' not in st.session_state:
    st.session_state.words = []
if 'deleted_words' not in st.session_state:
    st.session_state.deleted_words = []

# Function to fetch word details from an online dictionary
def fetch_word_details(word):
    url = f"https://www.dictionary.com/browse/{word}"
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, "html.parser")
        try:
            definition = soup.find("div", {"value": "1"}).text.strip()
        except AttributeError:
            definition = "Definition not found"

        try:
            ipa = soup.find("span", {"class": "pron-spell-content"}).text.strip()
        except AttributeError:
            ipa = None

        synonyms, antonyms, example_sentence = "Not found", "Not found", "Not found"
        # Fetch synonyms, antonyms and example sentences if available
        try:
            synonyms = ', '.join([syn.text for syn in soup.find_all("a", {"class": "css-1gyuw4i eh475bn0"})[:5]])
        except AttributeError:
            pass

        try:
            antonyms = ', '.join([ant.text for ant in soup.find_all("a", {"class": "css-lv3ht0 eh475bn0"})[:5]])
        except AttributeError:
            pass

        try:
            example_sentence = soup.find("div", {"class": "css-pnw38j e15kc6du6"}).text.strip()
        except AttributeError:
            pass

        return definition, ipa, synonyms, antonyms, example_sentence
    return "Definition not found", None, "Not found", "Not found", "Not found"

# Create columns for the main content and usage guide
col1, col2 = st.columns([3, 1])

with col1:
    # Display the title
    st.title("Darlbit Word Subsumption")

    # Upload CSV file
    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

    # Upload text file
    uploaded_text_file = st.file_uploader("í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ", type=["txt"])

    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.write("ì—…ë¡œë“œëœ ë°ì´í„°")
        st.dataframe(df)

        # Ensure all necessary columns are present
        required_columns = ['word', 'difficulty', 'topic', 'source', 'important']
        for col in required_columns:
            if col not in df.columns:
                df[col] = 'Unknown' if col != 'important' else False

        words = df['word'].tolist()
        for new_word in words:
            if new_word:
                word_details, ipa, synonyms, antonyms, example_sentence = fetch_word_details(new_word)

                new_word_entry = {
                    "word": new_word,
                    "part_of_speech": "Not found",
                    "example_sentence": example_sentence,
                    "synonyms": synonyms,
                    "antonyms": antonyms,
                    "image_url": "https://via.placeholder.com/150",
                    "difficulty": df.loc[df['word'] == new_word, 'difficulty'].values[0],
                    "topic": df.loc[df['word'] == new_word, 'topic'].values[0],
                    "source": df.loc[df['word'] == new_word, 'source'].values[0],
                    "important": df.loc[df['word'] == new_word, 'important'].values[0],
                    "definition": word_details,
                    "ipa": ipa
                }
                st.session_state.words.append(new_word_entry)
        st.success("CSV íŒŒì¼ì—ì„œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.experimental_rerun()  # Reload the page to reflect changes

    if uploaded_text_file is not None:
        text = uploaded_text_file.read().decode("utf-8")
        st.text_area("ì—…ë¡œë“œëœ í…ìŠ¤íŠ¸", text, height=200)

        if st.button("ì…ë ¥"):
            blob = TextBlob(text)
            words = list(set(blob.words))

            for new_word in words:
                word_details, ipa, synonyms, antonyms, example_sentence = fetch_word_details(new_word)

                new_word_entry = {
                    "word": new_word,
                    "part_of_speech": "Not found",
                    "example_sentence": example_sentence,
                    "synonyms": synonyms,
                    "antonyms": antonyms,
                    "image_url": "https://via.placeholder.com/150",
                    "difficulty": "Unknown",
                    "topic": "General",
                    "source": "Uploaded Text",
                    "important": False,
                    "definition": word_details,
                    "ipa": ipa
                }
                st.session_state.words.append(new_word_entry)
            st.success("í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.experimental_rerun()  # Reload the page to reflect changes

    # Filter options
    selected_difficulty = st.selectbox('ë‚œì´ë„ë¡œ í•„í„°', ['ëª¨ë‘', 'ì‰¬ì›€', 'ì¤‘ê°„', 'ì–´ë ¤ì›€'])
    selected_topic = st.text_input('ì£¼ì œë¡œ í•„í„°')
    show_deleted = st.checkbox('ì‚­ì œëœ ë‹¨ì–´ ë³´ê¸°')

    # Display the words in a table format
    def display_words(words):
        data = []
        for i, word_entry in enumerate(words):
            word_info = {
                "ë‹¨ì–´": word_entry["word"],
                "í’ˆì‚¬": word_entry['part_of_speech'],
                "ì˜ˆë¬¸": word_entry['example_sentence'],
                "ë™ì˜ì–´": word_entry['synonyms'],
                "ë°˜ì˜ì–´": word_entry['antonyms'],
                "ë‚œì´ë„": word_entry['difficulty'],
                "ì£¼ì œ": word_entry['topic'],
                "ì˜ˆë¬¸ ì¶œì²˜": word_entry['source'],
                "ì •ì˜": word_entry['definition'],
                "ë°œìŒê¸°í˜¸": word_entry['ipa'] if word_entry['ipa'] else "ì—†ìŒ",
                "ì¤‘ìš” ë‹¨ì–´": "ğŸŒŸ" if word_entry["important"] else ""
            }
            data.append(word_info)

            st.image(word_entry["image_url"], caption=word_entry["word"])

        df = pd.DataFrame(data)
        st.dataframe(df)

        # Download button for the data
        csv = df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="words.csv">CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'
        if st.button('CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ'):
            st.markdown(href, unsafe_allow_html=True)
            st.stop()

    filtered_words = st.session_state.words
    if selected_difficulty != 'ëª¨ë‘':
        filtered_words = [word for word in filtered_words if word['difficulty'] == selected_difficulty]
    if selected_topic:
        filtered_words = [word for word in filtered_words if selected_topic.lower() in word['topic'].lower()]

    display_words(filtered_words)

    if show_deleted:
        st.markdown("### ì‚­ì œëœ ë‹¨ì–´")
        display_words(st.session_state.deleted_words)

    if st.button('ëª¨ë“  ì‚­ì œëœ ë‹¨ì–´ ë³µì›'):
        st.session_state.words.extend(st.session_state.deleted_words)
        st.session_state.deleted_words = []
        st.experimental_rerun()

with col2:
    st.title("ì‚¬ìš©ë²•")
    st.markdown(
        """
        ### Darlbit Word Subsumption ì‚¬ìš©ë²•
        1. **CSV íŒŒì¼ ì—…ë¡œë“œ**: CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë‹¨ì–´ ëª©ë¡ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
            - í•„ìš”í•œ ì—´: `word`, `difficulty`, `topic`, `source`, `important`
        2. **í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ**: ë¶„ì„í•  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
        3. **ì…ë ¥ ë²„íŠ¼ í´ë¦­**: í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ 'ì…ë ¥' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.
        4. **ë‹¨ì–´ ëª©ë¡ í™•ì¸**: ì—…ë¡œë“œëœ ë‹¨ì–´ ëª©ë¡ì„ í…Œì´ë¸”ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        5. **í•„í„° ì‚¬ìš©**: ë‚œì´ë„ì™€ ì£¼ì œë¡œ ë‹¨ì–´ ëª©ë¡ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
        6. **ì‚­ì œëœ ë‹¨ì–´ ë³µì›**: ì‚­ì œëœ ë‹¨ì–´ë¥¼ ë³µì›í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        7. **ë°ì´í„° ë‹¤ìš´ë¡œë“œ**: ë‹¨ì–´ ëª©ë¡ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

        ### ì˜ˆì œ CSV íŒŒì¼
        ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì˜ˆì œ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì„¸ìš”.
        """
    )

    # Example CSV download
    example_data = {
        "word": ["cogitate", "perspicacious", "loquacious"],
        "difficulty": ["ì–´ë ¤ì›€", "ì¤‘ê°„", "ì‰¬ì›€"],
        "topic": ["thinking", "perception", "speaking"],
        "source": ["example.com", "example.com", "example.com"],
        "important": [True, False, True]
    }
    example_df = pd.DataFrame(example_data)
    example_csv = example_df.to_csv(index=False)
    b64_example = base64.b64encode(example_csv.encode()).decode()
    example_href = f'<a href="data:file/csv;base64,{b64_example}" download="example_words.csv">ì˜ˆì œ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ</a>'
    st.markdown(example_href, unsafe_allow_html=True)

    # Instructions to save data before closing the app
    st.markdown(
        """
        ### ë°ì´í„° ì €ì¥ ì•ˆë‚´
        ì•±ì„ ì¢…ë£Œí•˜ê¸° ì „ì— ë‹¨ì–´ ëª©ë¡ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì„¸ìš”. 
        ë‹¤ìŒ ë²ˆì— ì´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì´ì „ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """
    )

# Links at the bottom in a 2x2 grid
st.markdown("### ê´€ë ¨ ë§í¬")
link_data = [
    ("ğŸŒ", "ì‚¬ì´íŠ¸", "https://spiffy-fig-443.notion.site/Reason-of-Moon-c68af35321f24e418bec2b804adadf7a"),
    ("ğŸ¦", "Twitter", "https://twitter.com/reasonofmoon"),
    ("ğŸ“·", "Instagram", "https://www.instagram.com/darlsam37"),
    ("â–¶ï¸", "YouTube1", "https://www.youtube.com/@reasonofmoon"),
    ("â–¶ï¸", "YouTube2", "https://www.youtube.com/@meta_prompt"),
    ("ğŸŒ™", "Moonlang", "https://moonlang.com")
]

cols = st.columns(2)
for i, (emoji, name, url) in enumerate(link_data):
    with cols[i % 2]:
        st.markdown(f'<div class="link-box"><a href="{url}" target="_blank">{emoji} {name}</a></div>', unsafe_allow_html=True)
